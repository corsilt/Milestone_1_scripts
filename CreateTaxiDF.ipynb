{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "\n",
    "client = Client(n_workers=6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import dask\n",
    "import dask.dataframe as dd\n",
    "import dask.array as da\n",
    "import fastparquet\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dd.read_csv(os.path.join('data', 'yellow_tripdata_2010-*.csv'),\n",
    "                 parse_dates=['pickup_datetime','dropoff_datetime'],\n",
    "                 quoting=csv.QUOTE_NONE, encoding='utf-8', error_bad_lines=False,\n",
    "                 dtype={'trip_distance':'float64', 'store_and_fwd_flag':'object'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/heres-how-to-calculate-distance-between-2-geolocations-in-python-93ecab5bbba4\n",
    "def haversine_distance(row):\n",
    "    \n",
    "    lat1 = row['pickup_latitude']\n",
    "    lon1 = row['pickup_longitude']\n",
    "    lat2 = row['dropoff_latitude']\n",
    "    lon2 = row['dropoff_longitude']\n",
    "    \n",
    "    # https://stackoverflow.com/questions/19252588/how-do-i-test-for-null-list-entry-in-python-list\n",
    "    if not all(x for x in [lat1, lon1, lat2, lon2]):\n",
    "        return row['trip_distance']\n",
    "    \n",
    "    if not all(isinstance(x, float) for x in [lat1, lon1, lat2, lon2]):\n",
    "        return row['trip_distance']\n",
    "    \n",
    "    if len([*filter(lambda x: (x < 39.0) | (x > 42.0) , [lat1, lat2])]) > 0:\n",
    "        return row['trip_distance']\n",
    "    \n",
    "    if len([*filter(lambda x: (x < -77.0) | (x > -70.0) , [lon1, lon2])]) > 0:\n",
    "        return row['trip_distance']\n",
    "    \n",
    "    r = 6371\n",
    "    phi1 = np.radians(lat1)\n",
    "    phi2 = np.radians(lat2)\n",
    "    delta_phi = np.radians(lat2 - lat1)\n",
    "    delta_lambda = np.radians(lon2 - lon1)\n",
    "    a = np.sin(delta_phi / 2)**2 + np.cos(phi1) * np.cos(phi2) *   np.sin(delta_lambda / 2)**2\n",
    "    res = r * (2 * np.arctan2(np.sqrt(a), np.sqrt(1 - a)))    \n",
    "    \n",
    "    \n",
    "    if (row['trip_distance'] < .15) | (row['trip_distance'] > 80):\n",
    "        res = res\n",
    "    else:\n",
    "        res = row['trip_distance']   \n",
    "    \n",
    "    \n",
    "    return np.round(res, 2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comp_dates(series, dt):\n",
    "    if series < (dt + timedelta(days=-.25)):\n",
    "        return 'Week before'\n",
    "    elif series > (dt + timedelta(days=+.25)):\n",
    "        return 'Week after'\n",
    "    else:\n",
    "        return 'Current week'\n",
    "    \n",
    "# https://stackoverflow.com/questions/34099684/how-to-use-groupby-transform-across-multiple-columns\n",
    "def find_which_week(x):          \n",
    "    b = x['b_ts'].iloc[0]\n",
    "    # here a series is being passed to the comp_dates function through 'apply'\n",
    "    x['which_week'] = x['pickup_datetime_1min'].apply(comp_dates, args=([b]))    \n",
    "    return x\n",
    "\n",
    "\n",
    "def make_same_dates(df_gb):         \n",
    "    \n",
    "    # here a series is being passed to the comp_dates function through 'apply'\n",
    "    df_gb['pickup_datetime_same_time'] = df_gb.apply(\n",
    "        lambda row: row['pickup_datetime_1min']+ timedelta(days=+7) if row['which_week'] == 'Week before' else \\\n",
    "        row['pickup_datetime_1min']+ timedelta(days=-7) if row['which_week'] == 'Week after' else \\\n",
    "        row['pickup_datetime_1min'], axis=1\n",
    "    )   \n",
    "    return df_gb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_trip_distance_bins(row):\n",
    "    \n",
    "    dist = row['comp_trip_distance']\n",
    "    \n",
    "    if dist == 0:\n",
    "        res = 0\n",
    "    elif dist <= .25:\n",
    "        res = .25\n",
    "    elif dist <= .5:\n",
    "        res = .5\n",
    "    elif dist <= 1:\n",
    "        res = 1\n",
    "    elif dist <= 2:\n",
    "        res = 2\n",
    "    elif dist <= 4:\n",
    "        res = 4\n",
    "    elif dist <= 8:\n",
    "        res = 8\n",
    "    elif dist <= 16:\n",
    "        res = 16\n",
    "    elif dist <= 32:\n",
    "        res = 32\n",
    "    else:\n",
    "        res = 33\n",
    "    \n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "vendor_id                    0\n",
       "pickup_datetime              0\n",
       "dropoff_datetime             0\n",
       "passenger_count              0\n",
       "trip_distance                0\n",
       "pickup_longitude             0\n",
       "pickup_latitude              0\n",
       "rate_code                    0\n",
       "store_and_fwd_flag    88387448\n",
       "dropoff_longitude          110\n",
       "dropoff_latitude           110\n",
       "payment_type                 0\n",
       "fare_amount                  0\n",
       "surcharge                    0\n",
       "mta_tax                      0\n",
       "tip_amount                   0\n",
       "tolls_amount                 0\n",
       "total_amount                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df.isnull().sum().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "vendor_id                     object\n",
       "pickup_datetime       datetime64[ns]\n",
       "dropoff_datetime      datetime64[ns]\n",
       "passenger_count                int64\n",
       "trip_distance                float64\n",
       "pickup_longitude             float64\n",
       "pickup_latitude              float64\n",
       "rate_code                      int64\n",
       "store_and_fwd_flag            object\n",
       "dropoff_longitude            float64\n",
       "dropoff_latitude             float64\n",
       "payment_type                  object\n",
       "fare_amount                  float64\n",
       "surcharge                    float64\n",
       "mta_tax                      float64\n",
       "tip_amount                   float64\n",
       "tolls_amount                 float64\n",
       "total_amount                 float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting: 2021-05-12 16:44:27.673278\n",
      "2021-05-12 20:52:10.932664\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "start_time  = datetime.now()\n",
    "print(\"Starting: \" + str(start_time))\n",
    "\n",
    "\n",
    "\n",
    "orig_boundary_list = ['2010-01-17T11:51:00',\n",
    "                     '2010-01-24T15:05:00',\n",
    "                     '2010-01-25T06:01:00',\n",
    "                     '2010-01-25T16:51:00',\n",
    "                      '2010-01-26T00:51:00',\n",
    "                      '2010-02-23T06:51:00',\n",
    "                      '2010-02-25T02:51:00',\n",
    "                      '2010-03-12T07:51:00',\n",
    "                      '2010-03-12T11:51:00',\n",
    "                      '2010-03-14T09:26:00',\n",
    "                      '2010-03-15T00:28:00',\n",
    "                      '2010-03-22T05:00:00',\n",
    "                      '2010-03-23T14:16:00',\n",
    "                      '2010-03-25T22:51:00',\n",
    "                      '2010-03-28T19:51:00',\n",
    "                      '2010-04-09T00:51:00',\n",
    "                      '2010-04-16T18:51:00',\n",
    "                      '2010-04-24T23:51:00',\n",
    "                      '2010-04-26T08:51:00',\n",
    "                      '2010-04-27T10:51:00',\n",
    "                      '2010-05-02T23:51:00',\n",
    "                      '2010-05-03T13:51:00',\n",
    "                      '2010-05-08T08:15:00',\n",
    "                      '2010-05-11T22:51:00',\n",
    "                      '2010-05-12T06:51:00',\n",
    "                      '2010-05-14T09:32:00',\n",
    "                      '2010-05-18T03:51:00',\n",
    "                      '2010-05-24T12:51:00',\n",
    "                      '2010-06-09T09:51:00',\n",
    "                      '2010-06-10T12:51:00',\n",
    "                      '2010-06-13T13:51:00',\n",
    "                      '2010-06-16T23:51:00',\n",
    "                      '2010-06-22T17:51:00',\n",
    "                      '2010-07-13T11:13:00',\n",
    "                      '2010-07-14T08:33:00',\n",
    "                      '2010-07-14T22:49:00',\n",
    "                      '2010-07-19T08:05:00',\n",
    "                      '2010-07-23T09:51:00',\n",
    "                      '2010-07-23T19:41:00',\n",
    "                      '2010-07-25T13:51:00',\n",
    "                      '2010-07-29T05:51:00',\n",
    "                      '2010-07-29T11:51:00',\n",
    "                      '2010-08-12T08:06:00',\n",
    "                      '2010-08-15T13:51:00',\n",
    "                      '2010-08-16T01:51:00',\n",
    "                      '2010-08-16T16:51:00',\n",
    "                      '2010-08-22T12:51:00',\n",
    "                      '2010-08-23T03:59:00',\n",
    "                      '2010-08-24T21:51:00',\n",
    "                      '2010-09-12T13:51:00',\n",
    "                      '2010-09-13T16:51:00',\n",
    "                      '2010-09-16T15:51:00',\n",
    "                      '2010-09-22T18:53:00',\n",
    "                      '2010-09-27T06:21:00',\n",
    "                      '2010-09-28T10:00:00',\n",
    "                      '2010-09-30T03:51:00',\n",
    "                      '2010-10-01T01:53:00',\n",
    "                      '2010-10-01T13:53:00',\n",
    "                      '2010-10-04T02:51:00',\n",
    "                      '2010-10-05T22:51:00',\n",
    "                      '2010-10-11T17:53:00',\n",
    "                      '2010-10-14T14:53:00',\n",
    "                      '2010-10-26T22:53:00',\n",
    "                      '2010-10-27T13:51:00',\n",
    "                      '2010-10-27T19:25:00',\n",
    "                      '2010-10-27T23:51:00',\n",
    "                      '2010-11-04T01:53:00',\n",
    "                      '2010-11-07T12:51:00',\n",
    "                      '2010-11-10T08:51:00',\n",
    "                      '2010-11-15T18:36:00',\n",
    "                      '2010-11-16T03:48:00',\n",
    "                      '2010-11-16T20:06:00',\n",
    "                      '2010-11-25T12:53:00',\n",
    "                      '2010-11-26T00:13:00',\n",
    "                      '2010-11-30T11:53:00',\n",
    "                      '2010-12-01T01:47:00',\n",
    "                      '2010-12-01T20:53:00',\n",
    "                      '2010-12-12T00:53:00',\n",
    "                      '2010-12-12T16:00:00',\n",
    "                      '2010-12-26T09:51:00',                  \n",
    "                      #'2010-3-14T05:00:00',\n",
    "                      #'2010-11-07T05:00:00', \n",
    "                     ]\n",
    "\n",
    "pot_boundary_list = [datetime.strptime(str_date, '%Y-%m-%dT%H:%M:%S') for str_date in orig_boundary_list]\n",
    "\n",
    "pot_boundary_list_dst = [x + timedelta(hours=+1) if (datetime(2010, 3, 14, 2, 0, 0) <= x < datetime(2010, 11, 7, 1, 0, 0)) else x for x in pot_boundary_list]\n",
    "\n",
    "\n",
    "ddf_list = []\n",
    "\n",
    "for idx, b in enumerate(pot_boundary_list_dst):\n",
    "    \n",
    "    \n",
    "    \n",
    "    days_plus_minus = .25\n",
    "    \n",
    "    week_before_start = (b + timedelta(days=-days_plus_minus-7))\n",
    "    week_before_end = (b + timedelta(days=days_plus_minus-7))\n",
    "    current_week_start = (b + timedelta(days=-days_plus_minus))\n",
    "    current_week_end = (b + timedelta(days=days_plus_minus))\n",
    "    week_after_start = (b + timedelta(days=-days_plus_minus+7))\n",
    "    week_after_end = (b + timedelta(days=days_plus_minus+7)) \n",
    "    \n",
    "    df_d = df[ \\\n",
    "          ((df['pickup_datetime'] >= week_before_start) & (df['pickup_datetime'] < week_before_end)) \\\n",
    "          | ((df['pickup_datetime'] >= current_week_start) & (df['pickup_datetime'] < current_week_end)) \\\n",
    "          | ((df['pickup_datetime'] >= week_after_start) & (df['pickup_datetime'] < week_after_end))         \n",
    "         ]\n",
    "    \n",
    "    df_d['b_id'] = idx\n",
    "    df_d['b_ts'] = b\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    ddf_list.append(df_d)    \n",
    "\n",
    "    \n",
    "# https://sourcecodequery.com/example-method/dask.concat\n",
    "df_d = dd.concat(ddf_list)\n",
    "\n",
    "df_d['comp_trip_distance'] = df_d.apply(lambda row: haversine_distance(row), axis=1, meta=(None, 'float64'))\n",
    "\n",
    "df_d['comp_dist_bins'] = df_d.apply(lambda row: make_trip_distance_bins(row), axis=1, meta=(None, 'float64'))\n",
    "\n",
    "\n",
    "df_d['pickup_datetime_1min'] = df_d['pickup_datetime'].dt.round('1min')\n",
    "\n",
    "\n",
    "df_3w = df_d.groupby(['b_id', 'b_ts', 'pickup_datetime_1min', 'comp_dist_bins'])['vendor_id'].count().reset_index().compute()#.apply(lambda x: x.value_counts(), meta=pd.Series(dtype='int', name='vendor_id')).compute()\n",
    "df_3w.columns = ['b_id', 'b_ts', 'pickup_datetime_1min', 'dist_bin', 'rides_per_minute']\n",
    "\n",
    "df_3w = df_3w.groupby(['b_id']).apply(find_which_week)\n",
    "\n",
    "# remove first and last entry per week in attached to a boundary_id\n",
    "# because rounding causes each extreme timestamp to be undercounted\n",
    "df_3w = df_3w.groupby(['b_id', 'which_week'], as_index=False).apply(lambda group: group.iloc[1:-1, :])\n",
    "\n",
    "\n",
    "\n",
    "df_3w = df_3w.sort_values(by=['b_id', 'pickup_datetime_1min']).reset_index(drop=True)   \n",
    "\n",
    "df_3w['sequence']=df_3w.groupby(['b_id', 'which_week']).cumcount()+1\n",
    "\n",
    "df_3w = df_3w.groupby('b_id').apply(make_same_dates)\n",
    "\n",
    "\n",
    "\n",
    "print(datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3w.to_csv('data/3wboundaries-weather-dst-adj-bins.csv', index=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
