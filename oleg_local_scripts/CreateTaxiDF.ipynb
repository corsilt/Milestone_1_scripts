{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "cell_id": "00000-f2e0232a-ef4e-4048-9231-4f43f8e8412c",
    "deepnote_cell_type": "code"
   },
   "source": "from dask.distributed import Client\n\nclient = Client(n_workers=6)\n",
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00001-b77de45e-3a02-46df-af42-d81386ec69e1",
    "deepnote_cell_type": "code"
   },
   "source": "import csv\nimport os\nimport dask\nimport dask.dataframe as dd\nimport dask.array as da\nimport fastparquet\nimport pandas as pd\nimport altair as alt\nfrom datetime import datetime, timedelta\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom datetime import datetime",
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00002-e2ad4034-4d84-46e5-83ca-0e93d1d506fa",
    "deepnote_cell_type": "code"
   },
   "source": "df = dd.read_csv(os.path.join('data', 'yellow_tripdata_2010-*.csv'),\n                 parse_dates=['pickup_datetime','dropoff_datetime'],\n                 quoting=csv.QUOTE_NONE, encoding='utf-8', error_bad_lines=False,\n                 dtype={'trip_distance':'float64', 'store_and_fwd_flag':'object'})\n",
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00003-1a390100-574c-498e-b852-4068eb3369ad",
    "deepnote_cell_type": "code"
   },
   "source": "# https://towardsdatascience.com/heres-how-to-calculate-distance-between-2-geolocations-in-python-93ecab5bbba4\ndef haversine_distance(row):\n    \n    lat1 = row['pickup_latitude']\n    lon1 = row['pickup_longitude']\n    lat2 = row['dropoff_latitude']\n    lon2 = row['dropoff_longitude']\n    \n    # https://stackoverflow.com/questions/19252588/how-do-i-test-for-null-list-entry-in-python-list\n    if not all(x for x in [lat1, lon1, lat2, lon2]):\n        return row['trip_distance']\n    \n    if not all(isinstance(x, float) for x in [lat1, lon1, lat2, lon2]):\n        return row['trip_distance']\n    \n    if len([*filter(lambda x: (x < 39.0) | (x > 42.0) , [lat1, lat2])]) > 0:\n        return row['trip_distance']\n    \n    if len([*filter(lambda x: (x < -77.0) | (x > -70.0) , [lon1, lon2])]) > 0:\n        return row['trip_distance']\n    \n    r = 6371\n    phi1 = np.radians(lat1)\n    phi2 = np.radians(lat2)\n    delta_phi = np.radians(lat2 - lat1)\n    delta_lambda = np.radians(lon2 - lon1)\n    a = np.sin(delta_phi / 2)**2 + np.cos(phi1) * np.cos(phi2) *   np.sin(delta_lambda / 2)**2\n    res = r * (2 * np.arctan2(np.sqrt(a), np.sqrt(1 - a)))    \n    \n    \n    if (row['trip_distance'] < .15) | (row['trip_distance'] > 80):\n        res = res\n    else:\n        res = row['trip_distance']   \n    \n    \n    return np.round(res, 2)\n\n",
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00004-daab5872-7830-45cf-a28f-21af25a50c55",
    "deepnote_cell_type": "code"
   },
   "source": "def comp_dates(series, dt):\n    if series < (dt + timedelta(days=-.25)):\n        return 'Week before'\n    elif series > (dt + timedelta(days=+.25)):\n        return 'Week after'\n    else:\n        return 'Current week'\n    \n# https://stackoverflow.com/questions/34099684/how-to-use-groupby-transform-across-multiple-columns\ndef find_which_week(x):          \n    b = x['b_ts'].iloc[0]\n    # here a series is being passed to the comp_dates function through 'apply'\n    x['which_week'] = x['pickup_datetime_1min'].apply(comp_dates, args=([b]))    \n    return x\n\n\ndef make_same_dates(df_gb):         \n    \n    # here a series is being passed to the comp_dates function through 'apply'\n    df_gb['pickup_datetime_same_time'] = df_gb.apply(\n        lambda row: row['pickup_datetime_1min']+ timedelta(days=+7) if row['which_week'] == 'Week before' else \\\n        row['pickup_datetime_1min']+ timedelta(days=-7) if row['which_week'] == 'Week after' else \\\n        row['pickup_datetime_1min'], axis=1\n    )   \n    return df_gb",
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00005-d930607d-cc6f-48ad-adfa-9cdbd70bf4c3",
    "deepnote_cell_type": "code"
   },
   "source": "def make_trip_distance_bins(row):\n    \n    dist = row['comp_trip_distance']\n    \n    if dist == 0:\n        res = 0\n    elif dist <= .25:\n        res = .25\n    elif dist <= .5:\n        res = .5\n    elif dist <= 1:\n        res = 1\n    elif dist <= 2:\n        res = 2\n    elif dist <= 4:\n        res = 4\n    elif dist <= 8:\n        res = 8\n    elif dist <= 16:\n        res = 16\n    elif dist <= 32:\n        res = 32\n    else:\n        res = 33\n    \n    \n    return res",
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00006-a9f6f2c0-187d-42c1-a148-c1a8f0c82a68",
    "deepnote_cell_type": "code"
   },
   "source": "#df.isnull().sum().compute()",
   "execution_count": 39,
   "outputs": [
    {
     "data": {
      "text/plain": "vendor_id                    0\npickup_datetime              0\ndropoff_datetime             0\npassenger_count              0\ntrip_distance                0\npickup_longitude             0\npickup_latitude              0\nrate_code                    0\nstore_and_fwd_flag    88387448\ndropoff_longitude          110\ndropoff_latitude           110\npayment_type                 0\nfare_amount                  0\nsurcharge                    0\nmta_tax                      0\ntip_amount                   0\ntolls_amount                 0\ntotal_amount                 0\ndtype: int64"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00007-22e82dc3-5391-4c38-821e-77e46345bc54",
    "deepnote_cell_type": "code"
   },
   "source": "#df.dtypes",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "vendor_id                     object\npickup_datetime       datetime64[ns]\ndropoff_datetime      datetime64[ns]\npassenger_count                int64\ntrip_distance                float64\npickup_longitude             float64\npickup_latitude              float64\nrate_code                      int64\nstore_and_fwd_flag            object\ndropoff_longitude            float64\ndropoff_latitude             float64\npayment_type                  object\nfare_amount                  float64\nsurcharge                    float64\nmta_tax                      float64\ntip_amount                   float64\ntolls_amount                 float64\ntotal_amount                 float64\ndtype: object"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00008-780bbbc1-20c3-45c9-abc1-fa8dd6b64f09",
    "deepnote_cell_type": "code"
   },
   "source": "from datetime import datetime\n\nstart_time  = datetime.now()\nprint(\"Starting: \" + str(start_time))\n\n\n\norig_boundary_list = ['2010-01-17T11:51:00',\n                     '2010-01-24T15:05:00',\n                     '2010-01-25T06:01:00',\n                     '2010-01-25T16:51:00',\n                      '2010-01-26T00:51:00',\n                      '2010-02-23T06:51:00',\n                      '2010-02-25T02:51:00',\n                      '2010-03-12T07:51:00',\n                      '2010-03-12T11:51:00',\n                      '2010-03-14T09:26:00',\n                      '2010-03-15T00:28:00',\n                      '2010-03-22T05:00:00',\n                      '2010-03-23T14:16:00',\n                      '2010-03-25T22:51:00',\n                      '2010-03-28T19:51:00',\n                      '2010-04-09T00:51:00',\n                      '2010-04-16T18:51:00',\n                      '2010-04-24T23:51:00',\n                      '2010-04-26T08:51:00',\n                      '2010-04-27T10:51:00',\n                      '2010-05-02T23:51:00',\n                      '2010-05-03T13:51:00',\n                      '2010-05-08T08:15:00',\n                      '2010-05-11T22:51:00',\n                      '2010-05-12T06:51:00',\n                      '2010-05-14T09:32:00',\n                      '2010-05-18T03:51:00',\n                      '2010-05-24T12:51:00',\n                      '2010-06-09T09:51:00',\n                      '2010-06-10T12:51:00',\n                      '2010-06-13T13:51:00',\n                      '2010-06-16T23:51:00',\n                      '2010-06-22T17:51:00',\n                      '2010-07-13T11:13:00',\n                      '2010-07-14T08:33:00',\n                      '2010-07-14T22:49:00',\n                      '2010-07-19T08:05:00',\n                      '2010-07-23T09:51:00',\n                      '2010-07-23T19:41:00',\n                      '2010-07-25T13:51:00',\n                      '2010-07-29T05:51:00',\n                      '2010-07-29T11:51:00',\n                      '2010-08-12T08:06:00',\n                      '2010-08-15T13:51:00',\n                      '2010-08-16T01:51:00',\n                      '2010-08-16T16:51:00',\n                      '2010-08-22T12:51:00',\n                      '2010-08-23T03:59:00',\n                      '2010-08-24T21:51:00',\n                      '2010-09-12T13:51:00',\n                      '2010-09-13T16:51:00',\n                      '2010-09-16T15:51:00',\n                      '2010-09-22T18:53:00',\n                      '2010-09-27T06:21:00',\n                      '2010-09-28T10:00:00',\n                      '2010-09-30T03:51:00',\n                      '2010-10-01T01:53:00',\n                      '2010-10-01T13:53:00',\n                      '2010-10-04T02:51:00',\n                      '2010-10-05T22:51:00',\n                      '2010-10-11T17:53:00',\n                      '2010-10-14T14:53:00',\n                      '2010-10-26T22:53:00',\n                      '2010-10-27T13:51:00',\n                      '2010-10-27T19:25:00',\n                      '2010-10-27T23:51:00',\n                      '2010-11-04T01:53:00',\n                      '2010-11-07T12:51:00',\n                      '2010-11-10T08:51:00',\n                      '2010-11-15T18:36:00',\n                      '2010-11-16T03:48:00',\n                      '2010-11-16T20:06:00',\n                      '2010-11-25T12:53:00',\n                      '2010-11-26T00:13:00',\n                      '2010-11-30T11:53:00',\n                      '2010-12-01T01:47:00',\n                      '2010-12-01T20:53:00',\n                      '2010-12-12T00:53:00',\n                      '2010-12-12T16:00:00',\n                      '2010-12-26T09:51:00',                  \n                      #'2010-3-14T05:00:00',\n                      #'2010-11-07T05:00:00', \n                     ]\n\npot_boundary_list = [datetime.strptime(str_date, '%Y-%m-%dT%H:%M:%S') for str_date in orig_boundary_list]\n\npot_boundary_list_dst = [x + timedelta(hours=+1) if (datetime(2010, 3, 14, 2, 0, 0) <= x < datetime(2010, 11, 7, 1, 0, 0)) else x for x in pot_boundary_list]\n\n\nddf_list = []\n\nfor idx, b in enumerate(pot_boundary_list_dst):\n    \n    \n    \n    days_plus_minus = .25\n    \n    week_before_start = (b + timedelta(days=-days_plus_minus-7))\n    week_before_end = (b + timedelta(days=days_plus_minus-7))\n    current_week_start = (b + timedelta(days=-days_plus_minus))\n    current_week_end = (b + timedelta(days=days_plus_minus))\n    week_after_start = (b + timedelta(days=-days_plus_minus+7))\n    week_after_end = (b + timedelta(days=days_plus_minus+7)) \n    \n    df_d = df[ \\\n          ((df['pickup_datetime'] >= week_before_start) & (df['pickup_datetime'] < week_before_end)) \\\n          | ((df['pickup_datetime'] >= current_week_start) & (df['pickup_datetime'] < current_week_end)) \\\n          | ((df['pickup_datetime'] >= week_after_start) & (df['pickup_datetime'] < week_after_end))         \n         ]\n    \n    df_d['b_id'] = idx\n    df_d['b_ts'] = b\n    \n    \n\n\n    ddf_list.append(df_d)    \n\n    \n# https://sourcecodequery.com/example-method/dask.concat\ndf_d = dd.concat(ddf_list)\n\ndf_d['comp_trip_distance'] = df_d.apply(lambda row: haversine_distance(row), axis=1, meta=(None, 'float64'))\n\ndf_d['comp_dist_bins'] = df_d.apply(lambda row: make_trip_distance_bins(row), axis=1, meta=(None, 'float64'))\n\n\ndf_d['pickup_datetime_1min'] = df_d['pickup_datetime'].dt.round('1min')\n\n\ndf_3w = df_d.groupby(['b_id', 'b_ts', 'pickup_datetime_1min', 'comp_dist_bins'])['vendor_id'].count().reset_index().compute()#.apply(lambda x: x.value_counts(), meta=pd.Series(dtype='int', name='vendor_id')).compute()\ndf_3w.columns = ['b_id', 'b_ts', 'pickup_datetime_1min', 'dist_bin', 'rides_per_minute']\n\ndf_3w = df_3w.groupby(['b_id']).apply(find_which_week)\n\n# remove first and last entry per week in attached to a boundary_id\n# because rounding causes each extreme timestamp to be undercounted\ndf_3w = df_3w.groupby(['b_id', 'which_week'], as_index=False).apply(lambda group: group.iloc[1:-1, :])\n\n\n\ndf_3w = df_3w.sort_values(by=['b_id', 'pickup_datetime_1min']).reset_index(drop=True)   \n\ndf_3w['sequence']=df_3w.groupby(['b_id', 'which_week']).cumcount()+1\n\ndf_3w = df_3w.groupby('b_id').apply(make_same_dates)\n\n\n\nprint(datetime.now())",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Starting: 2021-05-12 16:44:27.673278\n2021-05-12 20:52:10.932664\n"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00009-b69c2d6f-1d1e-41ef-93eb-ac6278889053",
    "deepnote_cell_type": "code"
   },
   "source": "df_3w",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00010-e5c2e792-7105-4ea5-ad58-5d8b9f8ef2c1",
    "deepnote_cell_type": "code"
   },
   "source": "df_3w.to_csv('data/3wboundaries-weather-dst-adj-bins.csv', index=False )",
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00011-c015e19f-0630-473a-b980-033c83bbb4f9",
    "deepnote_cell_type": "code"
   },
   "source": "",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=e5c38169-dd81-4fdb-9628-d1699354129b' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
   "metadata": {
    "tags": [],
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown"
   }
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 1,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "deepnote_notebook_id": "c3f4d4b7-9f75-4a25-8fa0-ebe24dd66437",
  "deepnote": {},
  "deepnote_execution_queue": []
 }
}